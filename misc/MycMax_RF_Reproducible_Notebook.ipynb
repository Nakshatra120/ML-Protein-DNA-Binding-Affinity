{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29620603",
   "metadata": {},
   "source": [
    "# Myc/Max — Random Forest Reproducible Notebook\n",
    "\n",
    "This notebook reproduces Random Forest (RF) results and figures for the Myc/Max TF–DNA binding project. It follows the exact CLI workflow used in your repo (`torch_prep_kfold.py` → `run_model.py`) and adds notebook-native plots for:\n",
    "- Regression scatter vs. experimental ΔΔG_bind\n",
    "- Binary confusion matrix (from a threshold on ΔΔG_bind)\n",
    "- Feature importance (Gini and permutation)\n",
    "\n",
    "**Before you run:**\n",
    "1) Place your repository scripts at the project root (same directory structure as your docs):\n",
    "```\n",
    "project_root/\n",
    "├─ Inputs/                 # you provide\n",
    "│   ├─ REFERENCE.csv       # contains SEQUENCE_ID and LABEL_COL\n",
    "│   └─ FEATURE*.csv        # 8 MMGBSA components (and corrections) averaged by frame\n",
    "├─ Data/                   # will be created/used by scripts\n",
    "├─ Model/                  # models saved here\n",
    "├─ torch_prep_kfold.py\n",
    "├─ run_model.py\n",
    "└─ hyperopt.py             # optional\n",
    "```\n",
    "2) Activate the correct env (pandas, numpy, scikit-learn, scipy, matplotlib, seaborn optional).\n",
    "3) Update the **CONFIG** cell below to your actual column names and filenames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199aa76",
   "metadata": {},
   "source": [
    "## CONFIG — set your paths and identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90347771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>> EDIT THESE <<<<<\n",
    "PROJECT_ROOT = \".\"\n",
    "\n",
    "DATA_DIR = f\"{PROJECT_ROOT}/ML_models/ML_RF/Data\"\n",
    "MODEL_DIR = f\"{PROJECT_ROOT}/ML_models/ML_RF/Model\"\n",
    "INPUTS_DIR = f\"{PROJECT_ROOT}/ML_models/ML_RF/Inputs\"\n",
    "\n",
    "\n",
    "# # --- base dirs ---\n",
    "# REPO   = Path.cwd()\n",
    "# MLRF   = REPO / \"ML_models\" / \"ML_RF\"       # we will run from here\n",
    "# DATA   = MLRF / \"Data\"\n",
    "# MODEL  = MLRF / \"Model\"\n",
    "# INPUTS = MLRF / \"Inputs\"\n",
    "\n",
    "# DATA.mkdir(parents=True, exist_ok=True)\n",
    "# MODEL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # --- script path (yours is under Data) ---\n",
    "# TORCH_PREP = MLRF / \"Data\" / \"torch_prep_kfold.py\"   # <- as you stated\n",
    "\n",
    "###\n",
    "\n",
    "# ID + label columns\n",
    "SEQUENCE_ID = \"sequence\"      # e.g., 'sequence'\n",
    "LABEL_COL   = \"bind_avg\"      # e.g., 'bind_avg' for regression\n",
    "\n",
    "# Feature CSVs (provide one or more, joined on SEQUENCE_ID)\n",
    "FEATURE_FILES = [\n",
    "    f\"{INPUTS_DIR}/rawdat.csv\"\n",
    "    # add more if you split per-term CSVs\n",
    "]\n",
    "\n",
    "REFERENCE_FILE = f\"{INPUTS_DIR}/exp_data_all.csv\"   # contains SEQUENCE_ID + LABEL_COL\n",
    "\n",
    "# Split + CV knobs (align with best settings)\n",
    "TEST_PERCENT = 0.20\n",
    "KFOLD = 1\n",
    "NUM_REPEATS = 1\n",
    "KEEP_LAST_PERCENT = 0       # 0 = keep all\n",
    "NAVG = 50                   # average rows per sequence in chunks\n",
    "SCR_FRACTIONS = \"0.0\"       # naming uses only the first element\n",
    "\n",
    "# RF hyperparameters (example starting point; update if you have best params)\n",
    "N_ESTIMATORS = 300\n",
    "MAX_DEPTH = None           # or an int (e.g., 10)\n",
    "MAX_FEATURES = \"auto\"      # 'auto', 'sqrt', 0.5, etc.\n",
    "MIN_SAMPLES_SPLIT = 2\n",
    "MIN_SAMPLES_LEAF = 1\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Prefix + model type\n",
    "PREFIX = \"mycmax\"\n",
    "MODEL_TYPE = \"reg\"          # 'reg', 'bin', or 'mclass'\n",
    "\n",
    "# Plot/analysis knobs\n",
    "BINARY_THRESHOLD = 0.0      # threshold on ΔΔG_bind for confusion matrix\n",
    "DATA_SCALE = \"log\"          # if your run_model.py expects 'log' scaling flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbc575",
   "metadata": {},
   "source": [
    "## 1) Initial split (merge features + hold-out test by sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54fad5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./ML_models/ML_RF/Data/torch_prep_kfold.py --initial_split   --reference_file ./ML_models/ML_RF/Inputs/exp_data_all.csv   --ref_id_col sequence   --ref_label_col bind_avg   --filenames ./ML_models/ML_RF/Inputs/rawdat.csv   --feature_id_col sequence   --prefix mycmax --model_type reg   --test_percentage 0.2   --scramble_fractions 0.0\n",
      "\n",
      "CWD: /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity\n",
      "\n",
      "2025-09-08 16:16:32,435 - INFO - Loaded reference data: shape=(168, 2)\n",
      "2025-09-08 16:16:32,609 - INFO - Combined feature data => shape=(272160, 10)\n",
      "2025-09-08 16:16:32,620 - INFO - After merging => shape=(68040, 11)\n",
      "2025-09-08 16:16:32,957 - INFO - Scr=0.0: train => mycmax_reg_scr0p00_trn_final.csv, shape=(53460, 10)\n",
      "2025-09-08 16:16:32,958 - INFO - Scr=0.0: test  => mycmax_reg_scr0p00_tst_preprocess.csv, shape=(14580, 10)\n",
      "2025-09-08 16:16:32,958 - INFO - Initial split completed. Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess, shlex, pathlib, sys\n",
    "\n",
    "pathlib.Path(DATA_DIR).mkdir(exist_ok=True, parents=True)\n",
    "pathlib.Path(MODEL_DIR).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Build the CLI for initial split\n",
    "cmd = f\"\"\"python {PROJECT_ROOT}/ML_models/ML_RF/Data/torch_prep_kfold.py --initial_split   --reference_file {REFERENCE_FILE}   --ref_id_col {SEQUENCE_ID}   --ref_label_col {LABEL_COL}   --filenames {' '.join(FEATURE_FILES)}   --feature_id_col {SEQUENCE_ID}   --prefix {PREFIX} --model_type {MODEL_TYPE}   --test_percentage {TEST_PERCENT}   --scramble_fractions {SCR_FRACTIONS}\n",
    "\"\"\"\n",
    "print(cmd)\n",
    "# subprocess.run(shlex.split(cmd), check=False)  # uncomment to execute when your scripts are available\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "res = subprocess.run(\n",
    "    shlex.split(cmd),\n",
    "    check=True,                # raise on failure\n",
    "    capture_output=True,       # see stderr if it fails\n",
    "    text=True\n",
    ")\n",
    "print(res.stdout)\n",
    "print(res.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc747042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb7b145",
   "metadata": {},
   "source": [
    "## 2) Build repeated K-folds for training (standardize using training stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./ML_models/ML_RF/Data/torch_prep_kfold.py --process train   --keep_last_percent 0   --navg 50   --kfold 1 --num_repeats 1   --prefix mycmax --model_type reg   --scramble_fractions 0.0   --random_state 42\n",
      "\n",
      "CWD: /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', './ML_models/ML_RF/Data/torch_prep_kfold.py', '--process', 'train', '--keep_last_percent', '0', '--navg', '50', '--kfold', '1', '--num_repeats', '1', '--prefix', 'mycmax', '--model_type', 'reg', '--scramble_fractions', '0.0', '--random_state', '42']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# subprocess.run(shlex.split(cmd), check=False)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCWD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m----> 9\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshlex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# raise on failure\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# see stderr if it fails\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mmgbsa_ml/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', './ML_models/ML_RF/Data/torch_prep_kfold.py', '--process', 'train', '--keep_last_percent', '0', '--navg', '50', '--kfold', '1', '--num_repeats', '1', '--prefix', 'mycmax', '--model_type', 'reg', '--scramble_fractions', '0.0', '--random_state', '42']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "cmd = f\"\"\"python {PROJECT_ROOT}/ML_models/ML_RF/Data/torch_prep_kfold.py --process train   --keep_last_percent {KEEP_LAST_PERCENT}   --navg {NAVG}   --kfold {KFOLD} --num_repeats {NUM_REPEATS}   --prefix {PREFIX} --model_type {MODEL_TYPE}   --scramble_fractions {SCR_FRACTIONS}   --random_state {RANDOM_STATE}\n",
    "\"\"\"\n",
    "print(cmd)\n",
    "# subprocess.run(shlex.split(cmd), check=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "res = subprocess.run(\n",
    "    shlex.split(cmd),\n",
    "    check=True,                # raise on failure\n",
    "    capture_output=True,       # see stderr if it fails\n",
    "    text=True\n",
    ")\n",
    "print(res.stdout)\n",
    "print(res.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- args as a list ---\n",
    "args = [\n",
    "    sys.executable, str(TORCH_PREP),\n",
    "    \"--initial_split\",\n",
    "    \"--reference_file\", str(REFERENCE_FILE),\n",
    "    \"--ref_id_col\", SEQUENCE_ID,\n",
    "    \"--ref_label_col\", LABEL_COL,\n",
    "    \"--filenames\", *[str(p) for p in FEATURE_FILES],\n",
    "    \"--feature_id_col\", SEQUENCE_ID,\n",
    "    \"--prefix\", PREFIX,\n",
    "    \"--model_type\", MODEL_TYPE,\n",
    "    \"--test_percentage\", str(TEST_PERCENT),\n",
    "    \"--scramble_fractions\", SCR_FRAC,\n",
    "]\n",
    "\n",
    "print(\"Running from:\", MLRF)\n",
    "print(\"Script exists:\", TORCH_PREP.exists())\n",
    "res = subprocess.run(args, check=True, capture_output=True, text=True, cwd=str(MLRF))\n",
    "print(res.stdout)\n",
    "if res.stderr: print(\"[stderr]\", res.stderr)\n",
    "\n",
    "print(\"Expect outputs in:\", (MLRF / \"Data\").resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a5041",
   "metadata": {},
   "source": [
    "## 3) Train RF with cross‑validation (saves models + CV metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca95bf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./ML_models/ML_RF/run_model.py --mode 0   --model_type reg --data_scale log   --kfold 1 --num_repeats 1   --model_dir ./ML_models/ML_RF/Model --data_dir ./ML_models/ML_RF/Data   --output_file predictions   --ref_id_col sequence --ref_label_col bind_avg   --n_estimators 300 --max_depth None --max_features auto   --min_samples_split 2 --min_samples_leaf 1   --random_state 42   --prefix mycmax --scramble_fractions 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"\"\"python {PROJECT_ROOT}/ML_models/ML_RF/run_model.py --mode 0   --model_type {MODEL_TYPE} --data_scale {DATA_SCALE}   --kfold {KFOLD} --num_repeats {NUM_REPEATS}   --model_dir {MODEL_DIR} --data_dir {DATA_DIR}   --output_file predictions   --ref_id_col {SEQUENCE_ID} --ref_label_col {LABEL_COL}   --n_estimators {N_ESTIMATORS} --max_depth {str(MAX_DEPTH)} --max_features {MAX_FEATURES}   --min_samples_split {MIN_SAMPLES_SPLIT} --min_samples_leaf {MIN_SAMPLES_LEAF}   --random_state {RANDOM_STATE}   --prefix {PREFIX} --scramble_fractions {SCR_FRACTIONS}\n",
    "\"\"\"\n",
    "print(cmd)\n",
    "# subprocess.run(shlex.split(cmd), check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a26c9f",
   "metadata": {},
   "source": [
    "<add some comments that allow people to see that they are infact running the 5 fold cross validation>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52409005",
   "metadata": {},
   "source": [
    "## 4) Prepare the test set using the training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e0a287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./ML_models/ML_RF/Data/torch_prep_kfold.py --process test   --keep_last_percent 0   --navg 50   --prefix mycmax --model_type reg   --scramble_fractions 0.0   --random_state 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"\"\"python {PROJECT_ROOT}/ML_models/ML_RF/Data/torch_prep_kfold.py --process test   --keep_last_percent {KEEP_LAST_PERCENT}   --navg {NAVG}   --prefix {PREFIX} --model_type {MODEL_TYPE}   --scramble_fractions {SCR_FRACTIONS}   --random_state {RANDOM_STATE}\n",
    "\"\"\"\n",
    "print(cmd)\n",
    "# subprocess.run(shlex.split(cmd), check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f763a69",
   "metadata": {},
   "source": [
    "## 5) Evaluate saved models on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a3b578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./ML_models/ML_RF/run_model.py --mode 1   --model_type reg --data_scale log   --kfold 1 --num_repeats 1   --model_dir ./ML_models/ML_RF/Model --data_dir ./ML_models/ML_RF/Data   --output_file predictions   --ref_id_col sequence --ref_label_col bind_avg   --random_state 42   --prefix mycmax --scramble_fractions 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd = f\"\"\"python {PROJECT_ROOT}/ML_models/ML_RF/run_model.py --mode 1   --model_type {MODEL_TYPE} --data_scale {DATA_SCALE}   --kfold {KFOLD} --num_repeats {NUM_REPEATS}   --model_dir {MODEL_DIR} --data_dir {DATA_DIR}   --output_file predictions   --ref_id_col {SEQUENCE_ID} --ref_label_col {LABEL_COL}   --random_state {RANDOM_STATE}   --prefix {PREFIX} --scramble_fractions {SCR_FRACTIONS}\n",
    "\"\"\"\n",
    "print(cmd)\n",
    "# subprocess.run(shlex.split(cmd), check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9fbcf",
   "metadata": {},
   "source": [
    "## 6) Notebook-native plots to match the paper/supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84e9c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions: False ML_models/ML_RF/Data/predictions_reg_final_avg_scr0p00.csv\n",
      "Test predictions: False ML_models/ML_RF/Data/predictions_test_reg_scr0p00.csv\n",
      "[WARN] Missing: ML_models/ML_RF/Data/predictions_reg_final_avg_scr0p00.csv\n",
      "[WARN] Missing: ML_models/ML_RF/Data/predictions_test_reg_scr0p00.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Locate outputs produced by the pipeline ----\n",
    "cv_pred_path = Path(DATA_DIR) / f\"predictions_{MODEL_TYPE}_final_avg_scr0p00.csv\"\n",
    "tst_pred_path = Path(DATA_DIR) / f\"predictions_test_{MODEL_TYPE}_scr0p00.csv\"\n",
    "cv_metrics_path = Path(PROJECT_ROOT) / f\"final_metrics_{MODEL_TYPE}_trn_scr0p00.csv\"\n",
    "tst_metrics_path = Path(PROJECT_ROOT) / f\"final_metrics_{MODEL_TYPE}_tst_scr0p00.csv\"\n",
    "\n",
    "print(\"CV predictions:\", cv_pred_path.exists(), cv_pred_path)\n",
    "print(\"Test predictions:\", tst_pred_path.exists(), tst_pred_path)\n",
    "\n",
    "# ---- Load predictions (sequence-level) ----\n",
    "# Expected columns (example): sequence, y_true (experimental ΔΔG), y_pred (model ΔΔG)\n",
    "def _load_preds(path):\n",
    "    if path.exists():\n",
    "        df = pd.read_csv(path)\n",
    "        # Best guess for column names; adjust if your files use different names\n",
    "        # Try to infer\n",
    "        cols = df.columns.str.lower()\n",
    "        if 'y_true' not in cols.tolist() or 'y_pred' not in cols.tolist():\n",
    "            print(\"[Note] Please rename columns to include y_true and y_pred, or edit here.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"[WARN] Missing: {path}\")\n",
    "        return None\n",
    "\n",
    "cv_df = _load_preds(cv_pred_path)\n",
    "tst_df = _load_preds(tst_pred_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fae693",
   "metadata": {},
   "source": [
    "### 6A) Regression scatter (ΔΔG_bind: predicted vs experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, title=\"Regression (ΔΔG_bind)\"):\n",
    "    if df is None: \n",
    "        print(\"No dataframe provided.\")\n",
    "        return\n",
    "    # Infer columns\n",
    "    lc = df.columns.str.lower()\n",
    "    y_true_col = df.columns[lc.get_loc('y_true')] if 'y_true' in lc else df.columns[-2]\n",
    "    y_pred_col = df.columns[lc.get_loc('y_pred')] if 'y_pred' in lc else df.columns[-1]\n",
    "    x = df[y_true_col].values\n",
    "    y = df[y_pred_col].values\n",
    "\n",
    "    pcc, _ = pearsonr(x, y)\n",
    "    mse = mean_squared_error(x, y)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(x, y, alpha=0.7)\n",
    "    plt.axhline(0, linestyle='--')\n",
    "    plt.axvline(0, linestyle='--')\n",
    "    plt.title(f\"{title}\\nPearson={pcc:.2f}, MSE={mse:.2f}\")\n",
    "    plt.xlabel(\"Experimental ΔΔG_bind\")\n",
    "    plt.ylabel(\"Predicted ΔΔG_bind\")\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter(cv_df, title=\"Training CV (averaged predictions)\")\n",
    "plot_scatter(tst_df, title=\"Held‑out Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d63ae5",
   "metadata": {},
   "source": [
    "### 6B) Binary confusion matrix (threshold on ΔΔG_bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd474098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary_cm(df, threshold=0.0, title=\"Binary classification (ΔΔG threshold)\"):\n",
    "    if df is None: \n",
    "        print(\"No dataframe provided.\")\n",
    "        return\n",
    "    lc = df.columns.str.lower()\n",
    "    y_true_col = df.columns[lc.get_loc('y_true')] if 'y_true' in lc else df.columns[-2]\n",
    "    y_pred_col = df.columns[lc.get_loc('y_pred')] if 'y_pred' in lc else df.columns[-1]\n",
    "    y_true = (df[y_true_col].values > threshold).astype(int)\n",
    "    y_hat  = (df[y_pred_col].values > threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"non‑binding\",\"binding\"])\n",
    "    disp.plot(values_format='d')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_binary_cm(cv_df, threshold=BINARY_THRESHOLD, title=\"Training CV (threshold=0.0)\")\n",
    "plot_binary_cm(tst_df, threshold=BINARY_THRESHOLD, title=\"Held‑out Test (threshold=0.0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f084f70",
   "metadata": {},
   "source": [
    "### 6C) Feature importance (Gini + optional permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you saved per‑fold RF models, you can reload and average feature_importances_. \n",
    "# As a simple placeholder, this cell expects a CSV with per‑feature Gini importances if your pipeline produced it.\n",
    "# Otherwise, adapt to load your .pkl models from Model/ and extract .feature_importances_.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FEATURE_IMPORTANCE_CSV = Path(DATA_DIR) / \"rf_feature_importances_scr0p00.csv\"  # optional\n",
    "if FEATURE_IMPORTANCE_CSV.exists():\n",
    "    imp = pd.read_csv(FEATURE_IMPORTANCE_CSV)\n",
    "    # Expect columns: feature, gini_importance\n",
    "    imp = imp.sort_values('gini_importance', ascending=False)\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.bar(imp['feature'], imp['gini_importance'])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Gini importance\")\n",
    "    plt.title(\"Random Forest — Feature Importance (Gini)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"[Note] {FEATURE_IMPORTANCE_CSV} not found. If you have saved models, load them and compute importances here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30eb49",
   "metadata": {},
   "source": [
    "## 7) Reproducibility report — capture config + env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, json, pandas as pd\n",
    "report = {\n",
    "    \"python\": sys.version,\n",
    "    \"platform\": platform.platform(),\n",
    "    \"config\": {\n",
    "        \"PROJECT_ROOT\": PROJECT_ROOT,\n",
    "        \"DATA_DIR\": DATA_DIR,\n",
    "        \"MODEL_DIR\": MODEL_DIR,\n",
    "        \"INPUTS_DIR\": INPUTS_DIR,\n",
    "        \"SEQUENCE_ID\": SEQUENCE_ID,\n",
    "        \"LABEL_COL\": LABEL_COL,\n",
    "        \"TEST_PERCENT\": TEST_PERCENT,\n",
    "        \"KFOLD\": KFOLD,\n",
    "        \"NUM_REPEATS\": NUM_REPEATS,\n",
    "        \"KEEP_LAST_PERCENT\": KEEP_LAST_PERCENT,\n",
    "        \"NAVG\": NAVG,\n",
    "        \"SCR_FRACTIONS\": SCR_FRACTIONS,\n",
    "        \"RF\": {\n",
    "            \"n_estimators\": N_ESTIMATORS,\n",
    "            \"max_depth\": MAX_DEPTH,\n",
    "            \"max_features\": MAX_FEATURES,\n",
    "            \"min_samples_split\": MIN_SAMPLES_SPLIT,\n",
    "            \"min_samples_leaf\": MIN_SAMPLES_LEAF,\n",
    "            \"random_state\": RANDOM_STATE\n",
    "        },\n",
    "        \"MODEL_TYPE\": MODEL_TYPE,\n",
    "        \"PREFIX\": PREFIX,\n",
    "        \"DATA_SCALE\": DATA_SCALE\n",
    "    }\n",
    "}\n",
    "with open(\"/mnt/data/mycmax_rf_repro_config.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"Saved config to /mnt/data/mycmax_rf_repro_config.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmgbsa_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
