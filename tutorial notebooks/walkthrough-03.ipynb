{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e521624",
   "metadata": {},
   "source": [
    "# Protein–DNA ΔΔG: Neural Network (MLP) Walkthrough\n",
    "\n",
    "This notebook builds a **Neural Network baseline** using scikit-learn's `MLPRegressor`.\n",
    "It mirrors the Random Forest tutorial structure but adds NN-specific steps like scaling,\n",
    "early stopping, and training/validation loss curves.\n",
    "\n",
    "**Pipeline outline**\n",
    "1. Load & audit data (`rawdat.csv` + `exp_data_all.csv`).\n",
    "2. Merge on `SEQUENCE_ID`, align `LABEL_COL`.\n",
    "3. EDA: missingness, duplicates, dtypes, quick stats.\n",
    "4. Define features/target and standardize inputs.\n",
    "5. Train/validation split and **5-fold cross-validation** with a `Pipeline`.\n",
    "6. Fit a **baseline MLPRegressor** with **early stopping**.\n",
    "7. Evaluate (R², RMSE, MAE) on hold-out test set.\n",
    "8. Inspect training curves, cross-validated predictions.\n",
    "9. Model interpretation: **Permutation Importance** and **PDP**.\n",
    "10. Quick **RandomizedSearchCV** for better hyperparameters.\n",
    "11. Save artifacts (model, metrics, predictions, config).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c18ad9",
   "metadata": {},
   "source": [
    "## 0. Setup & Configuration\n",
    "\n",
    "Adjust paths if your repo layout differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13d1dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs dir: /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity/tutorial notebooks\n",
      "Outputs dir: /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity/tutorial notebooks/ML_NN_CV\n",
      "Feature file(s): [PosixPath('/Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity/tutorial notebooks/rawdat.csv')]\n",
      "Reference file: /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity/tutorial notebooks/exp_data_all.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Python stdlib ---\n",
    "import os, math, json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Data stack ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- scikit-learn ---\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict, RandomizedSearchCV, learning_curve\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "\n",
    "# --- Utils ---\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------- Project paths (Path objects only) --------\n",
    "PROJECT_ROOT = Path.cwd()          # or Path('.'), but keep as Path\n",
    "INPUTS_DIR   = PROJECT_ROOT\n",
    "OUTPUT_DIR   = PROJECT_ROOT / \"ML_NN_CV\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- Column identifiers --------\n",
    "SEQUENCE_ID = \"sequence\"    # Unique key across files\n",
    "LABEL_COL   = \"bind_avg\"    # ΔΔG label\n",
    "\n",
    "# -------- Input files (Path objects) --------\n",
    "FEATURE_FILES  = [INPUTS_DIR / \"rawdat.csv\"]        # list in case you add more later\n",
    "REFERENCE_FILE = INPUTS_DIR / \"exp_data_all.csv\"\n",
    "\n",
    "print(f\"Inputs dir: {INPUTS_DIR}\")\n",
    "print(f\"Outputs dir: {OUTPUT_DIR}\")\n",
    "print(f\"Feature file(s): {FEATURE_FILES}\")\n",
    "print(f\"Reference file: {REFERENCE_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246a2529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (68040, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>run</th>\n",
       "      <th>VDWAALS</th>\n",
       "      <th>EEL</th>\n",
       "      <th>EGB</th>\n",
       "      <th>ESURF</th>\n",
       "      <th>HB Energy</th>\n",
       "      <th>Hydrophobic Energy</th>\n",
       "      <th>Pi-Pi Energy</th>\n",
       "      <th>Delta_Entropy</th>\n",
       "      <th>bind_avg</th>\n",
       "      <th>binding_type</th>\n",
       "      <th>improving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA</td>\n",
       "      <td>9</td>\n",
       "      <td>-236.997</td>\n",
       "      <td>-1869.660</td>\n",
       "      <td>1823.216</td>\n",
       "      <td>-35.292</td>\n",
       "      <td>-2.590101</td>\n",
       "      <td>-156.445725</td>\n",
       "      <td>-4.282747</td>\n",
       "      <td>-24.750849</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA</td>\n",
       "      <td>9</td>\n",
       "      <td>-218.620</td>\n",
       "      <td>-1850.331</td>\n",
       "      <td>1807.831</td>\n",
       "      <td>-32.521</td>\n",
       "      <td>-2.977171</td>\n",
       "      <td>-142.709472</td>\n",
       "      <td>-7.240534</td>\n",
       "      <td>-25.235404</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA</td>\n",
       "      <td>9</td>\n",
       "      <td>-232.611</td>\n",
       "      <td>-1878.075</td>\n",
       "      <td>1834.181</td>\n",
       "      <td>-34.170</td>\n",
       "      <td>-3.105868</td>\n",
       "      <td>-145.088977</td>\n",
       "      <td>-8.856276</td>\n",
       "      <td>-25.124940</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA</td>\n",
       "      <td>9</td>\n",
       "      <td>-203.677</td>\n",
       "      <td>-1870.595</td>\n",
       "      <td>1823.641</td>\n",
       "      <td>-32.402</td>\n",
       "      <td>-3.414769</td>\n",
       "      <td>-150.961716</td>\n",
       "      <td>-5.338670</td>\n",
       "      <td>-23.079573</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA</td>\n",
       "      <td>9</td>\n",
       "      <td>-212.279</td>\n",
       "      <td>-1864.730</td>\n",
       "      <td>1820.462</td>\n",
       "      <td>-31.858</td>\n",
       "      <td>-3.571942</td>\n",
       "      <td>-146.583284</td>\n",
       "      <td>-7.171679</td>\n",
       "      <td>-22.812241</td>\n",
       "      <td>0.166339</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sequence  run  VDWAALS       EEL       EGB  \\\n",
       "0  CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA    9 -236.997 -1869.660  1823.216   \n",
       "1  CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA    9 -218.620 -1850.331  1807.831   \n",
       "2  CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA    9 -232.611 -1878.075  1834.181   \n",
       "3  CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA    9 -203.677 -1870.595  1823.641   \n",
       "4  CAGGGCTGGGTCCACCTCATGGCCTTTGTTCTGGAA    9 -212.279 -1864.730  1820.462   \n",
       "\n",
       "    ESURF  HB Energy  Hydrophobic Energy  Pi-Pi Energy  Delta_Entropy  \\\n",
       "0 -35.292  -2.590101         -156.445725     -4.282747     -24.750849   \n",
       "1 -32.521  -2.977171         -142.709472     -7.240534     -25.235404   \n",
       "2 -34.170  -3.105868         -145.088977     -8.856276     -25.124940   \n",
       "3 -32.402  -3.414769         -150.961716     -5.338670     -23.079573   \n",
       "4 -31.858  -3.571942         -146.583284     -7.171679     -22.812241   \n",
       "\n",
       "   bind_avg  binding_type  improving  \n",
       "0  0.166339             1          0  \n",
       "1  0.166339             1          0  \n",
       "2  0.166339             1          0  \n",
       "3  0.166339             1          0  \n",
       "4  0.166339             1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load feature data\n",
    "features = pd.read_csv(FEATURE_FILES[0])\n",
    "features[SEQUENCE_ID] = features[SEQUENCE_ID].str.replace(\"MycMax_\", \"\", regex=False)\n",
    "\n",
    "# Load reference labels\n",
    "labels = pd.read_csv(REFERENCE_FILE)\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(features, labels, on=SEQUENCE_ID, how=\"inner\")\n",
    "df = df.dropna(subset=[LABEL_COL])\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390468bf",
   "metadata": {},
   "source": [
    "## 2. Quick Data Audit\n",
    "\n",
    "We check:\n",
    "- dtypes and info\n",
    "- missing values per column\n",
    "- duplicate sequences (leakage risk)\n",
    "- quick numeric stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5d8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 68040 entries, 0 to 68039\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   sequence            68040 non-null  object \n",
      " 1   run                 68040 non-null  int64  \n",
      " 2   VDWAALS             68040 non-null  float64\n",
      " 3   EEL                 68040 non-null  float64\n",
      " 4   EGB                 68040 non-null  float64\n",
      " 5   ESURF               68040 non-null  float64\n",
      " 6   HB Energy           68040 non-null  float64\n",
      " 7   Hydrophobic Energy  68040 non-null  float64\n",
      " 8   Pi-Pi Energy        68040 non-null  float64\n",
      " 9   Delta_Entropy       68040 non-null  float64\n",
      " 10  bind_avg            68040 non-null  float64\n",
      " 11  binding_type        68040 non-null  int64  \n",
      " 12  improving           68040 non-null  int64  \n",
      "dtypes: float64(9), int64(3), object(1)\n",
      "memory usage: 7.3+ MB\n",
      "\n",
      "Missing values per column (top 20):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sequence              0\n",
       "run                   0\n",
       "VDWAALS               0\n",
       "EEL                   0\n",
       "EGB                   0\n",
       "ESURF                 0\n",
       "HB Energy             0\n",
       "Hydrophobic Energy    0\n",
       "Pi-Pi Energy          0\n",
       "Delta_Entropy         0\n",
       "bind_avg              0\n",
       "binding_type          0\n",
       "improving             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate sequence rows: 67998\n",
      "\n",
      "Descriptive stats (numeric):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>5.766324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDWAALS</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-201.378166</td>\n",
       "      <td>20.130228</td>\n",
       "      <td>-270.351000</td>\n",
       "      <td>-215.101000</td>\n",
       "      <td>-201.824000</td>\n",
       "      <td>-188.088000</td>\n",
       "      <td>-105.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEL</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-1898.996636</td>\n",
       "      <td>38.450855</td>\n",
       "      <td>-2076.822000</td>\n",
       "      <td>-1924.672000</td>\n",
       "      <td>-1897.880000</td>\n",
       "      <td>-1873.026000</td>\n",
       "      <td>-1758.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGB</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>1850.679788</td>\n",
       "      <td>35.684319</td>\n",
       "      <td>1722.168000</td>\n",
       "      <td>1826.616000</td>\n",
       "      <td>1849.566000</td>\n",
       "      <td>1874.488000</td>\n",
       "      <td>2013.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESURF</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-31.474066</td>\n",
       "      <td>2.393914</td>\n",
       "      <td>-43.027000</td>\n",
       "      <td>-33.082000</td>\n",
       "      <td>-31.535000</td>\n",
       "      <td>-29.954000</td>\n",
       "      <td>-18.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HB Energy</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-8.175591</td>\n",
       "      <td>6.065805</td>\n",
       "      <td>-30.470945</td>\n",
       "      <td>-13.585766</td>\n",
       "      <td>-4.378422</td>\n",
       "      <td>-3.275576</td>\n",
       "      <td>-0.324696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hydrophobic Energy</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-135.669642</td>\n",
       "      <td>13.021100</td>\n",
       "      <td>-181.225207</td>\n",
       "      <td>-144.756364</td>\n",
       "      <td>-136.267018</td>\n",
       "      <td>-127.247098</td>\n",
       "      <td>-65.594027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pi-Pi Energy</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-3.219995</td>\n",
       "      <td>2.584144</td>\n",
       "      <td>-17.248618</td>\n",
       "      <td>-4.999256</td>\n",
       "      <td>-2.974733</td>\n",
       "      <td>-0.964479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta_Entropy</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>-21.768632</td>\n",
       "      <td>2.156622</td>\n",
       "      <td>-33.004332</td>\n",
       "      <td>-23.182778</td>\n",
       "      <td>-21.798697</td>\n",
       "      <td>-20.392486</td>\n",
       "      <td>-9.803474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bind_avg</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>0.182705</td>\n",
       "      <td>0.834584</td>\n",
       "      <td>-0.862667</td>\n",
       "      <td>-0.511587</td>\n",
       "      <td>-0.027842</td>\n",
       "      <td>0.614097</td>\n",
       "      <td>2.035660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binding_type</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improving</th>\n",
       "      <td>68040.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count         mean        std          min          25%  \\\n",
       "run                 68040.0    10.500000   5.766324     1.000000     5.750000   \n",
       "VDWAALS             68040.0  -201.378166  20.130228  -270.351000  -215.101000   \n",
       "EEL                 68040.0 -1898.996636  38.450855 -2076.822000 -1924.672000   \n",
       "EGB                 68040.0  1850.679788  35.684319  1722.168000  1826.616000   \n",
       "ESURF               68040.0   -31.474066   2.393914   -43.027000   -33.082000   \n",
       "HB Energy           68040.0    -8.175591   6.065805   -30.470945   -13.585766   \n",
       "Hydrophobic Energy  68040.0  -135.669642  13.021100  -181.225207  -144.756364   \n",
       "Pi-Pi Energy        68040.0    -3.219995   2.584144   -17.248618    -4.999256   \n",
       "Delta_Entropy       68040.0   -21.768632   2.156622   -33.004332   -23.182778   \n",
       "bind_avg            68040.0     0.182705   0.834584    -0.862667    -0.511587   \n",
       "binding_type        68040.0     0.714286   0.795401     0.000000     0.000000   \n",
       "improving           68040.0     0.500000   0.500004     0.000000     0.000000   \n",
       "\n",
       "                            50%          75%          max  \n",
       "run                   10.500000    15.250000    20.000000  \n",
       "VDWAALS             -201.824000  -188.088000  -105.281000  \n",
       "EEL                -1897.880000 -1873.026000 -1758.701000  \n",
       "EGB                 1849.566000  1874.488000  2013.174000  \n",
       "ESURF                -31.535000   -29.954000   -18.292000  \n",
       "HB Energy             -4.378422    -3.275576    -0.324696  \n",
       "Hydrophobic Energy  -136.267018  -127.247098   -65.594027  \n",
       "Pi-Pi Energy          -2.974733    -0.964479     0.000000  \n",
       "Delta_Entropy        -21.798697   -20.392486    -9.803474  \n",
       "bind_avg              -0.027842     0.614097     2.035660  \n",
       "binding_type           0.500000     1.000000     2.000000  \n",
       "improving              0.500000     1.000000     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nDataFrame info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values per column (top 20):\")\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "display(missing.head(20))\n",
    "\n",
    "dup_count = df.duplicated(subset=[SEQUENCE_ID]).sum()\n",
    "print(f\"\\nDuplicate {SEQUENCE_ID} rows:\", dup_count)\n",
    "\n",
    "print(\"\\nDescriptive stats (numeric):\")\n",
    "display(df.describe().T.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28498653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "284e8d97",
   "metadata": {},
   "source": [
    "## 3. Define Features & Target\n",
    "\n",
    "We keep only **numeric** features (NN needs numeric inputs).  \n",
    "We **do not** scale the label here (ΔΔG is in its physical units).  \n",
    "Feature scaling will be handled in a `Pipeline` via `StandardScaler`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad8f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 11\n",
      "X shape: (68040, 11) | y shape: (68040,)\n",
      "Final feature count: 11\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c != LABEL_COL]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[LABEL_COL].copy()\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "\n",
    "# Drop constant columns (harmless but can slow training)\n",
    "const_cols = [c for c in feature_cols if X[c].nunique(dropna=False) <= 1]\n",
    "if const_cols:\n",
    "    print(\"Dropping constant columns:\", const_cols)\n",
    "    X = X.drop(columns=const_cols)\n",
    "    feature_cols = [c for c in feature_cols if c not in const_cols]\n",
    "\n",
    "print(\"Final feature count:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a9423",
   "metadata": {},
   "source": [
    "But in this formulation we also too the 'binding_type' and 'improving' columns as our features which we don't want since they are a form of label, not a feature that we train our ML model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped (non-feature) columns that were excluded: ['bind_avg', 'binding_type', 'improving', 'sequence']\n",
      "Number of features: 9\n",
      "X shape: (68040, 9) | y shape: (68040,)\n",
      "Final feature count: 9\n"
     ]
    }
   ],
   "source": [
    "# Explicit denylist of non-features / potential leakage columns\n",
    "LEAKAGE_COLS = {\n",
    "    SEQUENCE_ID,   # identifier\n",
    "    LABEL_COL,     # the true label ΔΔG\n",
    "    'binding_type',\n",
    "    'improving',\n",
    "    # add others here if you discover more helper/label-like columns\n",
    "}\n",
    "\n",
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove label/ID/leakage columns from features\n",
    "feature_cols = [c for c in numeric_cols if c not in LEAKAGE_COLS]\n",
    "\n",
    "# Build X/y\n",
    "X = df[feature_cols].copy()\n",
    "y = df[LABEL_COL].copy()\n",
    "\n",
    "print(\"Dropped (non-feature) columns that were excluded:\", sorted(list(set(LEAKAGE_COLS) & set(df.columns))))\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "print(\"X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "\n",
    "# Drop constant columns (can add noise / slow training)\n",
    "const_cols = [c for c in feature_cols if X[c].nunique(dropna=False) <= 1]\n",
    "if const_cols:\n",
    "    print(\"Dropping constant columns:\", const_cols)\n",
    "    X = X.drop(columns=const_cols)\n",
    "    feature_cols = [c for c in feature_cols if c not in const_cols]\n",
    "\n",
    "print(\"Final feature count:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f36fe5",
   "metadata": {},
   "source": [
    "### Leakage guard\n",
    "\n",
    "Sanity checks to ensure no leakage columns sneak into `X`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f513c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage guard passed ✅  (no forbidden columns in X)\n"
     ]
    }
   ],
   "source": [
    "leaky_in_X = sorted(list(set(['binding_type','improving', LABEL_COL, SEQUENCE_ID]) & set(X.columns)))\n",
    "assert len(leaky_in_X) == 0, f\"Leakage detected in features: {leaky_in_X}\"\n",
    "print(\"Leakage guard passed ✅  (no forbidden columns in X)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf9f574",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split (80/20)\n",
    "\n",
    "We keep a **hold-out** test set for honest final evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2076647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (54432, 11) Test: (13608, 11)\n",
      "Saved split indices -> /Users/nakku/Desktop/ML-Protein-DNA-Binding-Affinity/ML-Protein-DNA-Binding-Affinity/tutorial notebooks/ML_NN_CV/split_indices.csv\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, y, df[SEQUENCE_ID], test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# Save which sequences were in which split (traceability)\n",
    "split_path = OUTPUT_DIR / 'split_indices.csv'\n",
    "pd.DataFrame({SEQUENCE_ID: pd.concat([idx_train, idx_test]),\n",
    "              'split': ['train']*len(idx_train) + ['test']*len(idx_test)}).to_csv(split_path, index=False)\n",
    "print(\"Saved split indices ->\", split_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc28728",
   "metadata": {},
   "source": [
    "## 5. Sanity Baseline (Mean Predictor)\n",
    "\n",
    "A naive baseline that predicts the **training mean** of ΔΔG for all test samples.  \n",
    "This gives a floorline to beat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.full_like(y_test, fill_value=y_train.mean(), dtype=float)\n",
    "baseline_r2  = r2_score(y_test, y_mean)\n",
    "baseline_rmse = math.sqrt(mean_squared_error(y_test, y_mean))\n",
    "baseline_mae  = mean_absolute_error(y_test, y_mean)\n",
    "\n",
    "print(f\"Baseline — R²: {baseline_r2:.4f} | RMSE: {baseline_rmse:.4f} | MAE: {baseline_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c133c",
   "metadata": {},
   "source": [
    "## 6. Neural Network Pipeline\n",
    "\n",
    "We use a `Pipeline` so scaling happens **inside CV** (no leakage).  \n",
    "Baseline hyperparameters (good starting point):  \n",
    "- hidden_layer_sizes: (128, 64)  \n",
    "- activation: relu  \n",
    "- solver: adam  \n",
    "- alpha (L2): 1e-4  \n",
    "- batch_size: 64  \n",
    "- learning_rate_init: 1e-3  \n",
    "- early_stopping: True (uses an internal validation split)  \n",
    "- max_iter: 500, n_iter_no_change: 20  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=1e-4,\n",
    "    batch_size=64,\n",
    "    learning_rate_init=1e-3,\n",
    "    early_stopping=True,           # enables validation set inside fit\n",
    "    n_iter_no_change=20,\n",
    "    max_iter=500,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "    ('mlp', mlp)\n",
    "])\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Cross-validated metrics\n",
    "cv_r2  = cross_val_score(pipeline, X, y, cv=kf, scoring='r2', n_jobs=-1)\n",
    "cv_mse = cross_val_score(pipeline, X, y, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_mae = cross_val_score(pipeline, X, y, cv=kf, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "print(\"CV R²:\", cv_r2, \"\\nMean R²:\", cv_r2.mean())\n",
    "print(\"\\nCV RMSE:\", np.sqrt(-cv_mse), \"\\nMean RMSE:\", np.sqrt(-cv_mse).mean())\n",
    "print(\"\\nCV MAE:\", -cv_mae, \"\\nMean MAE:\", (-cv_mae).mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmgbsa_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
